---
title: "VLM-Social-Nav: Socially Aware Robot Navigation Through Scoring Using Vision-Language Models"
collection: publications
permalink: /publication/2024-12-04-vlm-social-nav
excerpt: 'This paper presents VLM-Social-Nav, a novel approach for socially aware robot navigation using vision-language models.'
date: 2024-12-04
venue: 'RA-L'
authors: ['Daeun Song', 'Jing Liang', 'Amirreza Payandeh', 'Amir Hossain Raj', 'Xuesu Xiao', 'Dinesh Manocha']
image: '/images/paper3.png'
links:
  - text: 'Paper'
    url: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10777573'
    icon: 'fa-solid fa-file-lines'
  - text: 'Video'
    url: 'https://youtu.be/dQaM-UVUsFw?si=RbZ1qhZADaBK9Ni1'
    icon: 'fa-solid fa-video'
paperurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10777573'
citation: 'Song, D., Liang, J., Payandeh, A., Raj, A. H., & Xiao, X. (2024). "VLM-Social-Nav: Socially Aware Robot Navigation Through Scoring Using Vision-Language Models." <i>RA-L 2024</i>.'
---
This paper presents VLM-Social-Nav, a novel approach for socially aware robot navigation using vision-language models. The method improves social navigation performance through advanced visual understanding.